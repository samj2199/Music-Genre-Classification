# -*- coding: utf-8 -*-
"""01_extract_mfccs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S32yp_5ugt9r14ncAkAba_SKE46rtaz3
"""

# Import necessary libraries
import os
import librosa
import math
import json

# Define constants for audio processing
AUDIO_DATA_PATH = r"../input/gtzan-dataset-music-genre-classification/Data/genres_original"
OUTPUT_JSON_PATH = r"mfcc_data.json"
SR = 22050  # Sample rate
TRACK_DURATION = 30  # Duration of each track in seconds
SAMPLES_PER_TRACK = SR * TRACK_DURATION

def extract_mfcc(audio_dir, json_file, num_mfcc=13, n_fft=2048, hop_length=512, num_slices=5):
    # Data storage dictionary
    audio_data = {
        "labels": [],
        "mfcc_features": [],
        "genre_mapping": [],
    }

    # Calculate samples and expected vectors per segment
    samples_per_slice = int(SAMPLES_PER_TRACK / num_slices)
    expected_vectors_per_slice = math.ceil(samples_per_slice / hop_length)

    # Traverse through all genre directories
    for idx, (path, _, files) in enumerate(os.walk(audio_dir)):
        # Check if not at the root directory
        if path != audio_dir:
            # Extract the genre label
            genre_label = path.split("/")[-1]
            audio_data["genre_mapping"].append(genre_label)
            print(f"Processing genre: {genre_label}")

            # Process audio files for a specific genre
            for file in files:
                file_path = os.path.join(path, file)
                signal, sample_rate = librosa.load(file_path, sr=SR)

                # Process segments of audio track
                for s in range(num_slices):
                    start_sample = samples_per_slice * s
                    end_sample = start_sample + samples_per_slice

                    # Extract MFCCs from segment
                    mfccs = librosa.feature.mfcc(signal[start_sample:end_sample],
                                                 sr=sample_rate,
                                                 n_fft=n_fft,
                                                 n_mfcc=num_mfcc,
                                                 hop_length=hop_length).T

                    # Store MFCCs if they have the expected length
                    if len(mfccs) == expected_vectors_per_slice:
                        audio_data["mfcc_features"].append(mfccs.tolist())
                        audio_data["labels"].append(idx-1)
                        print(f"File: {file_path}, segment: {s+1}")

    # Save extracted MFCCs to JSON
    with open(json_file, "w") as json_out:
        json.dump(audio_data, json_out, indent=4)

# Execute the MFCC extraction
extract_mfcc(AUDIO_DATA_PATH, OUTPUT_JSON_PATH, num_slices=10)